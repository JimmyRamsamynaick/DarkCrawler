# üìö Documentation API DarkCrawler

Cette documentation d√©taille toutes les classes, m√©thodes et fonctions disponibles dans DarkCrawler.

## üèóÔ∏è Architecture

```
DarkCrawler/
‚îú‚îÄ‚îÄ crawler/
‚îÇ   ‚îú‚îÄ‚îÄ detector.py      # DataLeakDetector
‚îÇ   ‚îú‚îÄ‚îÄ parser.py        # HTMLParser
‚îÇ   ‚îî‚îÄ‚îÄ tor_session.py   # TorSession
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ generator.py     # ReportGenerator
‚îÇ   ‚îî‚îÄ‚îÄ exporter.py      # ReportExporter
‚îú‚îÄ‚îÄ notifications/
‚îÇ   ‚îî‚îÄ‚îÄ realtime.py      # NotificationManager
‚îî‚îÄ‚îÄ alerts/
    ‚îú‚îÄ‚îÄ logger.py        # AlertLogger
    ‚îú‚îÄ‚îÄ email.py         # EmailAlert
    ‚îî‚îÄ‚îÄ webhook.py       # WebhookAlert
```

## üîç Module `crawler.detector`

### Classe `DataLeakDetector`

Classe principale pour la d√©tection de fuites de donn√©es.

#### Constructeur
```python
DataLeakDetector(config_path: str = None)
```

**Param√®tres:**
- `config_path` (str, optionnel): Chemin vers le fichier de configuration

**Exemple:**
```python
from crawler.detector import DataLeakDetector

# Avec configuration par d√©faut
detector = DataLeakDetector()

# Avec configuration personnalis√©e
detector = DataLeakDetector('config/custom_config.json')
```

#### M√©thodes

##### `scan_url(url: str) -> List[LeakDetection]`

Scanne une URL sp√©cifique pour d√©tecter des fuites.

**Param√®tres:**
- `url` (str): URL √† scanner (format .onion)

**Retour:**
- `List[LeakDetection]`: Liste des fuites d√©tect√©es

**Exceptions:**
- `ConnectionError`: Probl√®me de connexion Tor
- `TimeoutError`: Timeout de la requ√™te
- `ValueError`: URL invalide

**Exemple:**
```python
detector = DataLeakDetector()
results = detector.scan_url('http://example.onion')

for leak in results:
    print(f"Type: {leak.leak_type}")
    print(f"Contenu: {leak.content}")
    print(f"Position: {leak.position}")
```

##### `scan_multiple(urls: List[str]) -> Dict[str, List[LeakDetection]]`

Scanne plusieurs URLs en parall√®le.

**Param√®tres:**
- `urls` (List[str]): Liste des URLs √† scanner

**Retour:**
- `Dict[str, List[LeakDetection]]`: Dictionnaire {url: [fuites]}

**Exemple:**
```python
urls = ['http://site1.onion', 'http://site2.onion']
results = detector.scan_multiple(urls)

for url, leaks in results.items():
    print(f"{url}: {len(leaks)} fuites")
```

##### `detect_leaks(content: str, url: str = None) -> List[LeakDetection]`

D√©tecte des fuites dans du contenu texte.

**Param√®tres:**
- `content` (str): Contenu √† analyser
- `url` (str, optionnel): URL source du contenu

**Retour:**
- `List[LeakDetection]`: Liste des fuites d√©tect√©es

**Exemple:**
```python
content = "Contact: admin@company.com, Password: secret123"
leaks = detector.detect_leaks(content)
```

##### `add_custom_pattern(name: str, pattern: str, severity: str = 'medium')`

Ajoute un pattern de d√©tection personnalis√©.

**Param√®tres:**
- `name` (str): Nom du pattern
- `pattern` (str): Expression r√©guli√®re
- `severity` (str): Niveau de gravit√© ('low', 'medium', 'high', 'critical')

**Exemple:**
```python
detector.add_custom_pattern(
    'bitcoin_address',
    r'\b[13][a-km-zA-HJ-NP-Z1-9]{25,34}\b',
    'high'
)
```

### Classe `LeakDetection`

Repr√©sente une fuite d√©tect√©e.

#### Attributs
- `leak_type` (str): Type de fuite (email, password, phone, etc.)
- `content` (str): Contenu de la fuite
- `position` (int): Position dans le texte
- `context` (str): Contexte autour de la fuite
- `url` (str): URL source
- `severity` (str): Niveau de gravit√©
- `timestamp` (datetime): Moment de la d√©tection

#### M√©thodes

##### `to_dict() -> dict`

Convertit l'objet en dictionnaire.

**Exemple:**
```python
leak_dict = leak.to_dict()
print(leak_dict)
# {
#   'leak_type': 'email',
#   'content': 'admin@company.com',
#   'position': 245,
#   'context': 'Contact admin@company.com for support',
#   'url': 'http://example.onion',
#   'severity': 'medium',
#   'timestamp': '2024-01-17T14:30:22Z'
# }
```

## üåê Module `crawler.tor_session`

### Classe `TorSession`

G√®re les connexions via le r√©seau Tor.

#### Constructeur
```python
TorSession(proxy_host: str = '127.0.0.1', proxy_port: int = 9050)
```

#### M√©thodes

##### `get(url: str, timeout: int = 30) -> requests.Response`

Effectue une requ√™te GET via Tor.

**Exemple:**
```python
from crawler.tor_session import TorSession

session = TorSession()
response = session.get('http://example.onion')
print(response.text)
```

##### `is_tor_running() -> bool`

V√©rifie si Tor est accessible.

**Exemple:**
```python
if session.is_tor_running():
    print("‚úÖ Tor est accessible")
else:
    print("‚ùå Tor n'est pas accessible")
```

## üìä Module `reports.generator`

### Classe `ReportGenerator`

G√©n√®re des rapports dans diff√©rents formats.

#### M√©thodes

##### `generate_json_report(leaks: List[LeakDetection]) -> dict`

G√©n√®re un rapport au format JSON.

**Exemple:**
```python
from reports.generator import ReportGenerator

generator = ReportGenerator()
json_report = generator.generate_json_report(leaks)
```

##### `generate_markdown_report(leaks: List[LeakDetection]) -> str`

G√©n√®re un rapport au format Markdown.

**Exemple:**
```python
markdown_report = generator.generate_markdown_report(leaks)
with open('report.md', 'w') as f:
    f.write(markdown_report)
```

##### `generate_csv_report(leaks: List[LeakDetection]) -> str`

G√©n√®re un rapport au format CSV.

**Exemple:**
```python
csv_report = generator.generate_csv_report(leaks)
with open('report.csv', 'w') as f:
    f.write(csv_report)
```

##### `generate_statistics(leaks: List[LeakDetection]) -> dict`

G√©n√®re des statistiques sur les fuites.

**Retour:**
```python
{
    'total_leaks': 15,
    'by_type': {
        'email': 8,
        'password': 3,
        'phone': 4
    },
    'by_severity': {
        'high': 5,
        'medium': 7,
        'low': 3
    },
    'scan_duration': '2m 34s'
}
```

## üîî Module `notifications.realtime`

### Classe `NotificationManager`

G√®re les notifications en temps r√©el.

#### Constructeur
```python
NotificationManager()
```

#### M√©thodes de Configuration

##### `configure_slack(webhook_url: str)`

Configure les notifications Slack.

**Exemple:**
```python
from notifications.realtime import NotificationManager

manager = NotificationManager()
manager.configure_slack('https://hooks.slack.com/services/...')
```

##### `configure_email(smtp_server: str, smtp_port: int, username: str, password: str)`

Configure les notifications email.

**Exemple:**
```python
manager.configure_email(
    smtp_server='smtp.gmail.com',
    smtp_port=587,
    username='user@gmail.com',
    password='app_password'
)
```

##### `configure_discord(webhook_url: str)`

Configure les notifications Discord.

**Exemple:**
```python
manager.configure_discord('https://discord.com/api/webhooks/...')
```

#### M√©thodes d'Envoi

##### `send_notification(message: str, priority: str = 'medium', channels: List[str] = None, metadata: dict = None)`

Envoie une notification.

**Param√®tres:**
- `message` (str): Message √† envoyer
- `priority` (str): Priorit√© ('low', 'medium', 'high', 'critical')
- `channels` (List[str]): Canaux de notification
- `metadata` (dict): M√©tadonn√©es suppl√©mentaires

**Exemple:**
```python
manager.send_notification(
    message="üö® Fuite critique d√©tect√©e",
    priority="critical",
    channels=["slack", "email"],
    metadata={'leak_count': 15, 'url': 'http://example.onion'}
)
```

##### `send_leak_alert(leak: LeakDetection)`

Envoie une alerte pour une fuite sp√©cifique.

**Exemple:**
```python
for leak in detected_leaks:
    manager.send_leak_alert(leak)
```

## üö® Module `alerts.logger`

### Classe `AlertLogger`

G√®re les logs et alertes syst√®me.

#### M√©thodes

##### `log_detection(leak: LeakDetection)`

Enregistre une d√©tection dans les logs.

##### `log_scan_start(url: str)`

Enregistre le d√©but d'un scan.

##### `log_scan_complete(url: str, leak_count: int, duration: float)`

Enregistre la fin d'un scan.

**Exemple:**
```python
from alerts.logger import AlertLogger

logger = AlertLogger()
logger.log_scan_start('http://example.onion')

# ... scan ...

logger.log_scan_complete('http://example.onion', 15, 120.5)
```

## üìß Module `alerts.email`

### Classe `EmailAlert`

G√®re les alertes par email.

#### Constructeur
```python
EmailAlert(smtp_server: str, smtp_port: int, username: str, password: str)
```

#### M√©thodes

##### `send_alert(subject: str, message: str, recipients: List[str])`

Envoie un email d'alerte.

**Exemple:**
```python
from alerts.email import EmailAlert

email_alert = EmailAlert('smtp.gmail.com', 587, 'user@gmail.com', 'password')
email_alert.send_alert(
    subject='DarkCrawler Alert',
    message='15 fuites d√©tect√©es',
    recipients=['admin@company.com']
)
```

## üåê Module `alerts.webhook`

### Classe `WebhookAlert`

G√®re les alertes via webhooks.

#### M√©thodes

##### `send_slack_alert(webhook_url: str, message: str, priority: str = 'medium')`

Envoie une alerte Slack.

##### `send_discord_alert(webhook_url: str, message: str, priority: str = 'medium')`

Envoie une alerte Discord.

**Exemple:**
```python
from alerts.webhook import WebhookAlert

webhook = WebhookAlert()
webhook.send_slack_alert(
    'https://hooks.slack.com/services/...',
    'üö® 15 fuites d√©tect√©es sur http://example.onion',
    'high'
)
```

## üîß Utilitaires et Helpers

### Fonction `load_config(config_path: str) -> dict`

Charge un fichier de configuration.

**Exemple:**
```python
from config.loader import load_config

config = load_config('config/crawler_config.json')
print(config['tor']['proxy_port'])  # 9050
```

### Fonction `validate_onion_url(url: str) -> bool`

Valide une URL .onion.

**Exemple:**
```python
from utils.validators import validate_onion_url

if validate_onion_url('http://example.onion'):
    print("‚úÖ URL valide")
```

### Fonction `format_duration(seconds: float) -> str`

Formate une dur√©e en texte lisible.

**Exemple:**
```python
from utils.formatters import format_duration

duration = format_duration(125.5)
print(duration)  # "2m 5s"
```

## üß™ Tests et Mocking

### Classe `MockDetector`

D√©tecteur simul√© pour les tests.

**Exemple:**
```python
from tests.mocks import MockDetector

mock_detector = MockDetector()
mock_detector.add_mock_leak('email', 'test@example.com', 100)

results = mock_detector.scan_url('http://test.onion')
assert len(results) == 1
```

## üîí S√©curit√© et Bonnes Pratiques

### Gestion des Erreurs

Toutes les m√©thodes peuvent lever les exceptions suivantes:

- `ConnectionError`: Probl√®mes de r√©seau/Tor
- `TimeoutError`: Timeout des requ√™tes
- `ValueError`: Param√®tres invalides
- `ConfigurationError`: Erreurs de configuration
- `AuthenticationError`: Erreurs d'authentification (email, webhooks)

### Exemple de Gestion d'Erreurs
```python
from crawler.detector import DataLeakDetector
from crawler.exceptions import ConnectionError, TimeoutError

detector = DataLeakDetector()

try:
    results = detector.scan_url('http://example.onion')
except ConnectionError:
    print("‚ùå Impossible de se connecter via Tor")
except TimeoutError:
    print("‚è∞ Timeout de la requ√™te")
except ValueError as e:
    print(f"‚ùå Param√®tre invalide: {e}")
except Exception as e:
    print(f"‚ùå Erreur inattendue: {e}")
```

### Logging

Configuration recommand√©e pour les logs:

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('darkcrawler.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger('DarkCrawler')
```

## üìà Performance et Optimisation

### Conseils de Performance

1. **Limitation des threads**: Ne pas d√©passer 5 threads simultan√©s
2. **Timeout appropri√©**: 30-60 secondes selon la connexion
3. **Cache des r√©sultats**: √âviter de rescanner les m√™mes URLs
4. **Gestion m√©moire**: Traiter les gros volumes par batch

### Exemple d'Optimisation
```python
from concurrent.futures import ThreadPoolExecutor
from crawler.detector import DataLeakDetector

def scan_with_pool(urls, max_workers=3):
    detector = DataLeakDetector()
    results = {}
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {
            executor.submit(detector.scan_url, url): url 
            for url in urls
        }
        
        for future in future_to_url:
            url = future_to_url[future]
            try:
                results[url] = future.result(timeout=60)
            except Exception as e:
                results[url] = []
                print(f"Erreur {url}: {e}")
    
    return results
```

Cette documentation couvre l'ensemble de l'API DarkCrawler. Pour des exemples d'utilisation pratiques, consultez le fichier `EXAMPLES.md`.